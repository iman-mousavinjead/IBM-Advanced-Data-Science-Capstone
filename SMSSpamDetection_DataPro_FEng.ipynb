{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Spam detection in SMS data\n\n***(Data Processing and Feature Engineering Notebook)***"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Load Source Data from IBM Could Object Store\n\nwe need to connect to the object store and read a PARQUET file and create a dataframe out of it. "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# import required packages and libraries\nimport pyspark.sql.functions as fn\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover, StringIndexer, HashingTF, IDF, VectorAssembler, Normalizer\nfrom pyspark.ml import Pipeline\n\nimport ibmos2spark, os\n# @hidden_cell\ncredentials = {\n    'endpoint': 'https://s3.private.us.cloud-object-storage.appdomain.cloud',\n    'service_id': 'iam-ServiceId-83c6b79d-12e3-46ca-8755-655edce4d15b',\n    'iam_service_endpoint': 'https://iam.cloud.ibm.com/oidc/token',\n    'api_key': 'Qs6034fxfk78riRMCpVQXrKDrPzAlo6NUd_mP23rBmv3'\n}\n\nconfiguration_name = 'os_0fdd3f4f5bb549fab8a52672d7c21f58_configs'\ncos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\nsdf = spark.read.parquet(cos.url('SMSSpamData.parquet', 'advanceddatasciencecapstoneibm-donotdelete-pr-prnii9jvlql3tf'))\nsdf.createOrReplaceTempView('sdf')\nsdf.show(10, truncate=False)",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n|Label|Text                                                                                                                                                                        |Body_len|\n+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n|spam |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's                 |128     |\n|spam |FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, \u00a31.50 to rcv                         |116     |\n|spam |WINNER!! As a valued network customer you have been selected to receivea \u00a3900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.               |132     |\n|spam |Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030                  |126     |\n|spam |SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info                                    |111     |\n|spam |URGENT! You have won a 1 week FREE membership in our \u00a3100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18                 |130     |\n|spam |XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL                       |131     |\n|spam |England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/\u00fa1.20 POBOXox36504W45WQ 16+                 |132     |\n|spam |Thanks for your subscription to Ringtone UK your mobile will be charged \u00a35/month Please confirm by replying YES or NO. If you reply NO you will not be charged              |130     |\n|spam |07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. Please call now 08000930705 for delivery tomorrow|140     |\n+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\nonly showing top 10 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 4. Data Processing \n\nBelow, we perform some data processing steps to prepare data for training. Particularly, we'll use text processing which include:\n\n- Remove punctuations which are !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n- Tokenization: splits sentences into words and convert all words to lower case\n- Remove stop words which do not add much meaning to a sentence, such as the, he, she, have, ...\n- Convert categorical labels into numeric ones which will be later used for binary classification"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Remove punctuations which are !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\nsdf=sdf.withColumn('Text', fn.trim(fn.lower(fn.regexp_replace('Text', '\\p{Punct}', ''))))\nsdf.show(10, truncate=False)",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n|Label|Text                                                                                                                                                                   |Body_len|\n+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n|spam |free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005 text fa to 87121 to receive entry questionstd txt ratetcs apply 08452810075over18s                  |128     |\n|spam |freemsg hey there darling its been 3 weeks now and no word back id like some fun you up for it still tb ok xxx std chgs to send \u00a3150 to rcv                            |116     |\n|spam |winner as a valued network customer you have been selected to receivea \u00a3900 prize reward to claim call 09061701461 claim code kl341 valid 12 hours only                |132     |\n|spam |had your mobile 11 months or more u r entitled to update to the latest colour mobiles with camera for free call the mobile update co free on 08002986030               |126     |\n|spam |six chances to win cash from 100 to 20000 pounds txt csh11 and send to 87575 cost 150pday 6days 16 tsandcs apply reply hl 4 info                                       |111     |\n|spam |urgent you have won a 1 week free membership in our \u00a3100000 prize jackpot txt the word claim to no 81010 tc wwwdbuknet lccltd pobox 4403ldnw1a7rw18                    |130     |\n|spam |xxxmobilemovieclub to use your credit click the wap link in the next txt message or click here httpwap xxxmobilemovieclubcomnqjkgighjjgcbl                             |131     |\n|spam |england v macedonia  dont miss the goalsteam news txt ur national team to 87077 eg england to 87077 trywales scotland 4txt\u00fa120 poboxox36504w45wq 16                    |132     |\n|spam |thanks for your subscription to ringtone uk your mobile will be charged \u00a35month please confirm by replying yes or no if you reply no you will not be charged           |130     |\n|spam |07732584351  rodger burns  msg  we tried to call you re your reply to our sms for a free nokia mobile  free camcorder please call now 08000930705 for delivery tomorrow|140     |\n+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\nonly showing top 10 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Tokenization (Extracting words)\ntokenizer = Tokenizer().setInputCol('Text').setOutputCol('Tokens')\n\n# Remove the stopwords\nstopwords = StopWordsRemover().getStopWords()\nstopremover = StopWordsRemover().setStopWords(stopwords).setInputCol('Tokens').setOutputCol('Filtered_tokens')\n\n# Target indexer \nindexer = StringIndexer().setInputCol('Label').setOutputCol('bi_label')",
            "execution_count": 3,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 5. Vectorization and Feature Engineering\n\nWe need to get SMS texts into a form that a machine learning and or a deep learning model can actually use to understand and train a model. The process that converts text to a form that machine can understand is called **vectorizing**. This is defined as the process of encoding text as integers to create feature vectors. There are several vectorization methods. The most popular ones are\n\n- **Count vectorizing**: a document term matrix is generated where each cell is the count corresponding to the news title indicating the number of times a word appears in a document, also known as the term frequency.\n\n\n- **N-gram vectorizing**: similar to the count vectorization technique, in the N-Gram method, a document term matrix is generated and each cell represents the count. The difference in the N-grams method is that the count represents the combination of adjacent words of length n in the title. \n\n\n- **Term Frequency-Inverse Document Frequency (TF-IDF) vectorizing**: Similar to the count vectorization method, in the TF-IDF method, a document term matrix is generated and each column represents a single unique word. The difference in the TF-IDF method is that each cell doesn\u2019t indicate the term frequency, but the cell value represents a weighting that highlights the importance of that particular word to the document.\n\nIn our problem, we are going to use **(TF-IDF) vectorizer** from *Mlib* in *Apache Spark*. For further details, visit [Apache Spark Extracting, transforming and selecting features](https://spark.apache.org/docs/latest/ml-features.html)\n\nFurthermore, we are going to combine the features generated by **(TF-IDF) vectorizer** and that we created before, i.e., **Body_len**. To do so, we use **VectorAssembler** transformer from *Apache Spark MLib*. For further details, visit [Apache Spark Feature Transformers](https://spark.apache.org/docs/latest/ml-features.html#feature-transformers)"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Term Frequency-Inverse Document Frequency (TF-IDF) Vectorizer\nhashingTF = HashingTF(inputCol=\"Filtered_tokens\", outputCol=\"rawFeatures\", numFeatures=3000)\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"tf_idf_features\")\n\n#Vectore assembler\nassembler = VectorAssembler(inputCols=[\"Body_len\", \"tf_idf_features\"], outputCol=\"features\")",
            "execution_count": 4,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now, we create a **pipeline** so that we can apply all the above-mentined data pre-processing and feature engineering steps to our dataset, except for the punctuation removal, which has been done before applying the pipeline. "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pipeline = Pipeline(stages = [tokenizer, stopremover, hashingTF, idf, assembler, indexer])\nsdf_pro = pipeline.fit(sdf)\nsdf_pre=sdf_pro.transform(sdf)\nsdf_transformed=sdf_pre.drop(\"Label\",\"Text\",\"Body_len\",\"Tokens\",\"Filtered_tokens\",\"rawFeatures\", \"tf_idf_features\")\nsdf_transformed.show()",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+--------------------+--------+\n|            features|bi_label|\n+--------------------+--------+\n|(3001,[0,161,170,...|     1.0|\n|(3001,[0,331,564,...|     1.0|\n|(3001,[0,44,147,2...|     1.0|\n|(3001,[0,147,217,...|     1.0|\n|(3001,[0,14,98,10...|     1.0|\n|(3001,[0,214,215,...|     1.0|\n|(3001,[0,17,452,1...|     1.0|\n|(3001,[0,373,469,...|     1.0|\n|(3001,[0,100,432,...|     1.0|\n|(3001,[0,26,100,1...|     1.0|\n|(3001,[0,100,174,...|     1.0|\n|(3001,[0,56,147,4...|     1.0|\n|(3001,[0,57,147,2...|     1.0|\n|(3001,[0,57,87,12...|     1.0|\n|(3001,[0,666,1071...|     1.0|\n|(3001,[0,129,147,...|     1.0|\n|(3001,[0,170,427,...|     1.0|\n|(3001,[0,129,147,...|     1.0|\n|(3001,[0,44,129,4...|     1.0|\n|(3001,[0,147,236,...|     1.0|\n+--------------------+--------+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Store Feature Engineered Data in IBM Cloud Object Store\n\nLet's store our feature engineered data into the IBM Cloud Object store so that we can use it in the next step of our process i.e. Model Definition and Training."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "sdf_transformed = sdf_transformed.repartition(1)\nsdf_transformed.write.parquet(cos.url('SMSSpamData_Transformed.parquet', 'advanceddatasciencecapstoneibm-donotdelete-pr-prnii9jvlql3tf'))",
            "execution_count": 6,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now that the data has been stored in the IBM Cloud Object store, let us check and confirm that the stored data is looking good."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "sdf_Transformed_stored = spark.read.parquet(cos.url('SMSSpamData_Transformed.parquet', 'advanceddatasciencecapstoneibm-donotdelete-pr-prnii9jvlql3tf'))\nsdf_Transformed_stored.show()",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+--------------------+--------+\n|            features|bi_label|\n+--------------------+--------+\n|(3001,[0,161,170,...|     1.0|\n|(3001,[0,331,564,...|     1.0|\n|(3001,[0,44,147,2...|     1.0|\n|(3001,[0,147,217,...|     1.0|\n|(3001,[0,14,98,10...|     1.0|\n|(3001,[0,214,215,...|     1.0|\n|(3001,[0,17,452,1...|     1.0|\n|(3001,[0,373,469,...|     1.0|\n|(3001,[0,100,432,...|     1.0|\n|(3001,[0,26,100,1...|     1.0|\n|(3001,[0,100,174,...|     1.0|\n|(3001,[0,56,147,4...|     1.0|\n|(3001,[0,57,147,2...|     1.0|\n|(3001,[0,57,87,12...|     1.0|\n|(3001,[0,666,1071...|     1.0|\n|(3001,[0,129,147,...|     1.0|\n|(3001,[0,170,427,...|     1.0|\n|(3001,[0,129,147,...|     1.0|\n|(3001,[0,44,129,4...|     1.0|\n|(3001,[0,147,236,...|     1.0|\n+--------------------+--------+\nonly showing top 20 rows\n\n",
                    "name": "stdout"
                }
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python39",
            "display_name": "Python 3.9 with Spark",
            "language": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.7",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}